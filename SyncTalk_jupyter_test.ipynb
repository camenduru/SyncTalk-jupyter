{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/SyncTalk-jupyter/blob/main/SyncTalk_jupyter_test.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/SyncTalk\n",
        "%cd /content/SyncTalk\n",
        "\n",
        "!apt -y install -qq libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg aria2\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/SyncTalk/resolve/main/May.zip -d /content/SyncTalk/data -o May.zip\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/SyncTalk/resolve/main/trial_may.zip -d /content/SyncTalk/model -o trial_may.zip\n",
        "%cd /content/SyncTalk/data\n",
        "!unzip May.zip\n",
        "%cd /content/SyncTalk/model\n",
        "!unzip trial_may.zip\n",
        "\n",
        "!pip install -q https://github.com/camenduru/wheels/releases/download/colab2/pytorch3d-0.7.6-cp310-cp310-linux_x86_64.whl\n",
        "!pip install -q torch-ema ninja trimesh tensorboardX PyMCubes dearpygui scikit-learn face_alignment python_speech_features\n",
        "!pip install -q resampy pyaudio einops configargparse lpips onnxruntime-gpu facenet_pytorch fvcore iopath ffmpeg-python\n",
        "!pip install -q https://github.com/camenduru/wheels/releases/download/colab2/freqencoder-0.0.0-cp310-cp310-linux_x86_64.whl\n",
        "!pip install -q https://github.com/camenduru/wheels/releases/download/colab2/shencoder-0.0.0-cp310-cp310-linux_x86_64.whl\n",
        "!pip install -q https://github.com/camenduru/wheels/releases/download/colab2/gridencoder-0.0.0-cp310-cp310-linux_x86_64.whl\n",
        "!pip install -q https://github.com/camenduru/wheels/releases/download/colab2/raymarching_face-0.0.0-cp310-cp310-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/SyncTalk\n",
        "\n",
        "from nerf_triplane.provider import NeRFDataset\n",
        "from nerf_triplane.utils import *\n",
        "from nerf_triplane.network import NeRFNetwork\n",
        "\n",
        "try:\n",
        "    torch.backends.cuda.matmul.allow_tf32 = False\n",
        "    torch.backends.cudnn.allow_tf32 = False\n",
        "except AttributeError as e:\n",
        "    print('Info. This pytorch version is not support with tf32.')\n",
        "\n",
        "class Options:\n",
        "    def __init__(self):\n",
        "        self.path = None\n",
        "        self.O = False\n",
        "        self.test = False\n",
        "        self.test_train = False\n",
        "        self.data_range = [0, -1]\n",
        "        self.workspace = 'workspace'\n",
        "        self.seed = 0\n",
        "\n",
        "        ### training options\n",
        "        self.iters = 200000\n",
        "        self.lr = 1e-2\n",
        "        self.lr_net = 1e-3\n",
        "        self.ckpt = 'latest'\n",
        "        self.num_rays = 4096 * 16\n",
        "        self.cuda_ray = False\n",
        "        self.max_steps = 16\n",
        "        self.num_steps = 16\n",
        "        self.upsample_steps = 0\n",
        "        self.update_extra_interval = 16\n",
        "        self.max_ray_batch = 4096\n",
        "\n",
        "        ### loss set\n",
        "        self.warmup_step = 10000\n",
        "        self.amb_aud_loss = 1\n",
        "        self.amb_eye_loss = 1\n",
        "        self.unc_loss = 1\n",
        "        self.lambda_amb = 1e-1\n",
        "        self.pyramid_loss = 0\n",
        "\n",
        "        ### network backbone options\n",
        "        self.fp16 = False\n",
        "        self.bg_img = ''\n",
        "        self.fbg = False\n",
        "        self.exp_eye = False\n",
        "        self.fix_eye = -1\n",
        "        self.smooth_eye = False\n",
        "        self.bs_area = \"upper\"\n",
        "        self.torso_shrink = 0.8\n",
        "\n",
        "        ### dataset options\n",
        "        self.color_space = 'srgb'\n",
        "        self.preload = 0\n",
        "        self.bound = 1\n",
        "        self.scale = 4\n",
        "        self.offset = [0, 0, 0]\n",
        "        self.dt_gamma = 1/256\n",
        "        self.min_near = 0.05\n",
        "        self.density_thresh = 10\n",
        "        self.density_thresh_torso = 0.01\n",
        "        self.patch_size = 1\n",
        "\n",
        "        self.init_lips = False\n",
        "        self.finetune_lips = False\n",
        "        self.smooth_lips = False\n",
        "\n",
        "        self.torso = False\n",
        "        self.head_ckpt = ''\n",
        "\n",
        "        ### GUI options\n",
        "        self.gui = False\n",
        "        self.W = 450\n",
        "        self.H = 450\n",
        "        self.radius = 3.35\n",
        "        self.fovy = 21.24\n",
        "        self.max_spp = 1\n",
        "\n",
        "        ### else\n",
        "        self.att = 2\n",
        "        self.aud = ''\n",
        "        self.emb = False\n",
        "        self.portrait = False\n",
        "        self.ind_dim = 4\n",
        "        self.ind_num = 20000\n",
        "        self.ind_dim_torso = 8\n",
        "        self.amb_dim = 2\n",
        "        self.part = False\n",
        "        self.part2 = False\n",
        "        self.train_camera = False\n",
        "        self.smooth_path = False\n",
        "        self.smooth_path_window = 7\n",
        "\n",
        "        self.asr = False\n",
        "        self.asr_wav = ''\n",
        "        self.asr_play = False\n",
        "        self.asr_model = 'deepspeech'\n",
        "        self.asr_save_feats = False\n",
        "        self.fps = 50\n",
        "        self.l = 10\n",
        "        self.m = 50\n",
        "        self.r = 10\n",
        "\n",
        "opt = Options()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "opt.test = True\n",
        "opt.test_train = True\n",
        "opt.portrait = True\n",
        "opt.aud = '/content/SyncTalk/demo/test.wav'\n",
        "\n",
        "if opt.test and False:\n",
        "    opt.smooth_path = True\n",
        "    opt.smooth_eye = True\n",
        "    opt.smooth_lips = True\n",
        "\n",
        "metrics = [PSNRMeter(), LPIPSMeter(device=device), LMDMeter(backend='fan')]\n",
        "trainer = Trainer('ngp', opt, model, device=device, workspace=opt.workspace, criterion=criterion, fp16=opt.fp16, metrics=metrics, use_checkpoint=opt.ckpt)\n",
        "test_set = NeRFDataset(opt, device=device, type='train')\n",
        "test_set.training = False \n",
        "test_set.num_rays = -1\n",
        "test_loader = test_set.dataloader()\n",
        "model.aud_features = test_loader._data.auds\n",
        "model.eye_areas = test_loader._data.eye_area\n",
        "trainer.test(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "opt.iters = 100000\n",
        "opt.finetune_lips = True\n",
        "opt.patch_size = 64\n",
        "\n",
        "optimizer = lambda model: torch.optim.AdamW(model.get_params(opt.lr, opt.lr_net), betas=(0, 0.99), eps=1e-8)\n",
        "train_loader = NeRFDataset(opt, device=device, type='train').dataloader()\n",
        "assert len(train_loader) < opt.ind_num, f\"[ERROR] dataset too many frames: {len(train_loader)}, please increase --ind_num to this number!\"\n",
        "\n",
        "model.aud_features = train_loader._data.auds\n",
        "model.eye_area = train_loader._data.eye_area\n",
        "model.poses = train_loader._data.poses\n",
        "\n",
        "if opt.finetune_lips:\n",
        "    scheduler = lambda optimizer: optim.lr_scheduler.LambdaLR(optimizer, lambda iter: 0.05 ** (iter / opt.iters))\n",
        "else:\n",
        "    scheduler = lambda optimizer: optim.lr_scheduler.LambdaLR(optimizer, lambda iter: 0.5 ** (iter / opt.iters))\n",
        "\n",
        "metrics = [PSNRMeter(), LPIPSMeter(device=device),LMDMeter(backend='fan')]\n",
        "\n",
        "eval_interval = max(1, int(5000 / len(train_loader)))\n",
        "trainer = Trainer('ngp', opt, model, device=device, workspace=opt.workspace, optimizer=optimizer, criterion=criterion, ema_decay=0.95, fp16=opt.fp16, lr_scheduler=scheduler, scheduler_update_every_step=True, metrics=metrics, use_checkpoint=opt.ckpt, eval_interval=eval_interval)\n",
        "with open(os.path.join(opt.workspace, 'opt.txt'), 'a') as f:\n",
        "    f.write(str(opt))\n",
        "\n",
        "valid_loader = NeRFDataset(opt, device=device, type='val', downscale=1).dataloader()\n",
        "max_epochs = np.ceil(opt.iters / len(train_loader)).astype(np.int32)\n",
        "print(f'[INFO] max_epoch = {max_epochs}')\n",
        "trainer.train(train_loader, valid_loader, max_epochs)\n",
        "\n",
        "del train_loader, valid_loader\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "test_loader = NeRFDataset(opt, device=device, type='test').dataloader()\n",
        "trainer.test(test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
